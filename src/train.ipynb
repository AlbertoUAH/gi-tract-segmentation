{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## -- UW-Madison GI Tract Image Segmentation - MobileNetv2 + Data Augmentation + 2.5d version\n## -- Authors: Sergio Dominguez Rodriguez & Alberto Fernandez Hernandez\n## -- Objective: Second Model -> UNet","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:16:58.202148Z","iopub.execute_input":"2022-07-13T18:16:58.202477Z","iopub.status.idle":"2022-07-13T18:16:58.231512Z","shell.execute_reply.started":"2022-07-13T18:16:58.202394Z","shell.execute_reply":"2022-07-13T18:16:58.230809Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# [UW-Madison GI Tract Image Segmentation - Notebook for train phase: MobileNetV2](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/)\n> Track healthy organs in medical scans to improve cancer treatment\n\n<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/27923/logos/header.png?t=2021-06-02-20-30-25\">","metadata":{"id":"dR5Q6ojngVbr"}},{"cell_type":"markdown","source":"# ðŸ›  Install Libraries","metadata":{}},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch\n!pip install -qU wandb","metadata":{"id":"gS0cMWlKgVbt","outputId":"f887754f-9b12-443d-d8f9-8e601f4bf254","execution":{"iopub.status.busy":"2022-07-13T18:17:00.752642Z","iopub.execute_input":"2022-07-13T18:17:00.752974Z","iopub.status.idle":"2022-07-13T18:17:35.056229Z","shell.execute_reply.started":"2022-07-13T18:17:00.752925Z","shell.execute_reply":"2022-07-13T18:17:35.055337Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“š Import Libraries ","metadata":{}},{"cell_type":"code","source":"# -- Libraries\nfrom   matplotlib              import pyplot as plt\nfrom   sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\nfrom   sklearn.model_selection import train_test_split\nfrom   skimage                 import color\nfrom   matplotlib.patches      import Rectangle\nfrom   tqdm                    import tqdm\nimport matplotlib.gridspec     as gridspec\nimport matplotlib.patches      as mpatches\nimport segmentation_models_pytorch as smp\nimport tqdm.notebook           as tq\nimport matplotlib              as mpl\nimport numpy                   as np\nimport pandas                  as pd\nimport torch.nn                as nn\nimport albumentations          as A\nimport itertools\nimport warnings\nimport wandb\nimport random\nimport torch\nimport glob\nimport math\nimport gc\nimport cv2\nimport ast\nimport re\nimport os\n\nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')\n\n# -- Constants\nROOT_PATH    = '../input/uw-madison-gi-tract-image-segmentation/'\nTRAIN_PATH   = glob.glob(ROOT_PATH + '/train/*')\nTEST_PATH    = glob.glob(ROOT_PATH + '/test/')\nMASKS_PATH   = glob.glob('../input/uwmgi-mask-dataset/np/uw-madison-gi-tract-image-segmentation/train/*/*/*/*.npy')\nMODEL_NAME   = '03_uw_madison_seg_manet_25d_bce_dice_loss_error_plus_data_aug.pth'\nENCODER         = 'efficientnet-b1'\nENCODER_WEIGHTS = 'imagenet'\nACTIVATION      = 'sigmoid'\nIMG_SIZE     = (224, 224)\nLOSS_IMPROVE = 1e-04\nPATIENT      = 6\nRANDOM_STATE = 1234\nNUM_WORKERS  = 4\nBATCH_SIZE   = 32\nEPOCHS       = 50","metadata":{"id":"ckRoRTumgVbu","execution":{"iopub.status.busy":"2022-07-13T18:17:35.058302Z","iopub.execute_input":"2022-07-13T18:17:35.059192Z","iopub.status.idle":"2022-07-13T18:17:51.584821Z","shell.execute_reply.started":"2022-07-13T18:17:35.059151Z","shell.execute_reply":"2022-07-13T18:17:51.584037Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# â­ WandB: Weights & Biases\n\nWeights & Biases (W&B) is MLOps platform for tracking our experiemnts. We can use it to Build better models faster with experiment tracking, dataset versioning, and model management. Some of the cool features of W&B:\n\n* Track, compare, and visualize ML experiments\n\n* Get live metrics, terminal logs, and system stats streamed to the centralized dashboard.\n\n* Explain how your model works, show graphs of how model versions improved, discuss bugs, and demonstrate progress towards milestones.","metadata":{"id":"SnTN6d0jgVbv"}},{"cell_type":"code","source":"# -- wandb connection\ntry:\n    wandb.login(key=\"6e9dd2f54a703008450bc4e8c31d96dc6ef9d6e8\")\n    anonymous = None\nexcept:\n    anonymous = \"must\"\n    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"id":"kcXRYLqjgVby","execution":{"iopub.status.busy":"2022-07-13T18:17:51.586372Z","iopub.execute_input":"2022-07-13T18:17:51.586767Z","iopub.status.idle":"2022-07-13T18:17:53.285586Z","shell.execute_reply.started":"2022-07-13T18:17:51.586729Z","shell.execute_reply":"2022-07-13T18:17:53.284896Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# ðŸŒ± Set seed for reproducibility","metadata":{"id":"4F2YNhiLgVby"}},{"cell_type":"code","source":"# To ensure reproducibility\nnp.random.seed(RANDOM_STATE)\nrandom.seed(RANDOM_STATE)\ntorch.manual_seed(RANDOM_STATE)\ntorch.cuda.manual_seed(RANDOM_STATE)\n# When running on the CuDNN backend, two further options must be set\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n# Set a fixed value for the hash seed\nos.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\nprint('> SEEDING DONE')","metadata":{"id":"lp5G-IH1gVb0","execution":{"iopub.status.busy":"2022-07-13T18:17:53.287820Z","iopub.execute_input":"2022-07-13T18:17:53.288090Z","iopub.status.idle":"2022-07-13T18:17:53.297385Z","shell.execute_reply.started":"2022-07-13T18:17:53.288055Z","shell.execute_reply":"2022-07-13T18:17:53.296429Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"id":"dhkQYqtQgVb1"}},{"cell_type":"code","source":"def get_metadata(row):\n    data = row['id'].split('_')\n    case = int(data[0].replace('case',''))\n    day = int(data[1].replace('day',''))\n    slice_ = int(data[-1])\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row\n\ndef path2info(row):\n    path = row['image_path']\n    data = path.split('/')\n    slice_ = int(data[-1].split('_')[1])\n    case = int(data[-3].split('_')[0].replace('case',''))\n    day = int(data[-3].split('_')[1].replace('day',''))\n    width = int(data[-1].split('_')[2])\n    height = int(data[-1].split('_')[3])\n    row['height'] = height\n    row['width'] = width\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row","metadata":{"id":"KOIIiaRCgVb1","execution":{"iopub.status.busy":"2022-07-13T18:17:53.299217Z","iopub.execute_input":"2022-07-13T18:17:53.299612Z","iopub.status.idle":"2022-07-13T18:17:53.309038Z","shell.execute_reply.started":"2022-07-13T18:17:53.299527Z","shell.execute_reply":"2022-07-13T18:17:53.308029Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"id":"z6gBLRN5gVb7","execution":{"iopub.status.busy":"2022-07-13T18:17:53.310347Z","iopub.execute_input":"2022-07-13T18:17:53.312029Z","iopub.status.idle":"2022-07-13T18:17:53.323142Z","shell.execute_reply.started":"2022-07-13T18:17:53.311990Z","shell.execute_reply":"2022-07-13T18:17:53.322286Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"* First label: __Large bowel__\n* Second label: __Small bowel__\n* Third label: __Stomach__","metadata":{"id":"c0I1EEo0gVb8"}},{"cell_type":"code","source":"# -- Read .csv train dataframe\ntrain_df = pd.read_csv('../input/uwmgi-mask-dataset/train.csv')\ntrain_df = train_df[~(train_df['id'].str.contains('case7_day0')) & \\\n                    ~(train_df['id'].str.contains('case81_day30'))]\ntrain_df['segmentation'] = train_df.segmentation.fillna('')\ntrain_df['rle_len']      = train_df.segmentation.map(len)\ntrain_df['mask_path']    = train_df.mask_path.str.replace('/png/','/np').str.replace('.png','.npy')\n\ntrain_df_2 = train_df.groupby(['id'])['segmentation'].agg(list).to_frame().reset_index()\ntrain_df_2 = train_df_2.merge(train_df.groupby(['id'])['rle_len'].agg(sum).to_frame().reset_index())\n\n# -- First label: Large bowel\n# -- Second label: Small bowel\n# -- Third label: Stomach\ntrain_df_prepared = train_df.drop(columns=['segmentation', 'class', 'rle_len'])\ntrain_df_prepared = train_df_prepared.groupby(['id']).head(1).reset_index(drop=True)\ntrain_df_prepared = train_df_prepared.merge(train_df_2, on=['id'])\ntrain_df_prepared['empty'] = (train_df_prepared.rle_len==0) # empty masks\ntrain_df_prepared['segmentation'] = train_df_prepared['segmentation'].apply(lambda x: '_'.join([label for i, label \\\n                                                                              in enumerate(['LargeBowel', 'SmallBowel', 'Stomach'])\\\n                                                                              if x[i] != '']))\ntrain_df_prepared['segmentation'] = train_df_prepared['segmentation'].apply(lambda x: 'Empty' if x == '' else x)\nchannels=3\nstride=1\nfor i in range(channels):\n    train_df_prepared[f'image_path_{i:02}'] = train_df_prepared.groupby(['case','day'])['image_path'].shift(-i*stride).fillna(method=\"ffill\")\ntrain_df_prepared['image_paths'] = train_df_prepared[[f'image_path_{i:02d}' for i in range(channels)]].values.tolist()\ntrain_df_prepared.head()","metadata":{"id":"v-_qKGUxgVb8","execution":{"iopub.status.busy":"2022-07-13T18:17:53.324478Z","iopub.execute_input":"2022-07-13T18:17:53.324721Z","iopub.status.idle":"2022-07-13T18:17:56.145105Z","shell.execute_reply.started":"2022-07-13T18:17:53.324690Z","shell.execute_reply":"2022-07-13T18:17:56.144132Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Create folders","metadata":{}},{"cell_type":"code","source":"N_FOLD = 5\nskf = StratifiedGroupKFold(n_splits=N_FOLD, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df_prepared, train_df_prepared['empty'], groups = train_df_prepared[\"case\"])):\n    train_df_prepared.loc[val_idx, 'fold'] = fold\ndisplay(train_df_prepared.groupby(['fold','empty'])['id'].count())","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:17:56.146895Z","iopub.execute_input":"2022-07-13T18:17:56.147211Z","iopub.status.idle":"2022-07-13T18:17:56.315810Z","shell.execute_reply.started":"2022-07-13T18:17:56.147175Z","shell.execute_reply":"2022-07-13T18:17:56.314901Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Add extra Data Augmentation","metadata":{}},{"cell_type":"code","source":"data_transforms = {\n    \"train\": A.Compose([\n        A.HorizontalFlip(p=0.2),\n        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=25, p=0.4),\n        A.RandomCrop(height=round(IMG_SIZE[0] * 0.85), width=round(IMG_SIZE[1] * 0.85), always_apply=True),\n        A.Blur(blur_limit=3, p=0.1),\n        A.GaussNoise(var_limit=0.001, p=0.1),\n        A.Resize(*IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n        A.CoarseDropout(max_holes=8, max_height=IMG_SIZE[0]//20, max_width=IMG_SIZE[1]//20,\n                        min_holes=1, fill_value=0, mask_fill_value=0, p=0.1)\n    ]),\n    \"train_resize\": A.Compose([\n        A.Resize(*IMG_SIZE, interpolation=cv2.INTER_NEAREST)\n    ], p=1.0),\n    \"valid_resize\": A.Compose([\n        A.Resize(*IMG_SIZE, interpolation=cv2.INTER_NEAREST)\n    ], p=1.0),\n    \"valid\": A.Compose([\n        A.CenterCrop(height=round(IMG_SIZE[0] * 0.85), width=round(IMG_SIZE[1] * 0.85)),\n        A.Resize(*IMG_SIZE, interpolation=cv2.INTER_NEAREST)\n    ], p=1.0)\n}","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:17:56.317459Z","iopub.execute_input":"2022-07-13T18:17:56.317797Z","iopub.status.idle":"2022-07-13T18:17:56.328233Z","shell.execute_reply.started":"2022-07-13T18:17:56.317742Z","shell.execute_reply":"2022-07-13T18:17:56.327380Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Custom Data Loader","metadata":{"id":"_FFlaN7VgVb9"}},{"cell_type":"code","source":"def show_img(img, mask=None):\n    plt.imshow(img, cmap='bone')\n    \n    if mask is not None:\n        plt.imshow(mask, alpha=0.5)\n        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), \n                                                             (0.0,0.667,0.0), \n                                                             (0.0,0.0,0.667)]]\n        labels = [ \"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n        plt.legend(handles,labels)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:17:56.331561Z","iopub.execute_input":"2022-07-13T18:17:56.332460Z","iopub.status.idle":"2022-07-13T18:17:56.340318Z","shell.execute_reply.started":"2022-07-13T18:17:56.332349Z","shell.execute_reply":"2022-07-13T18:17:56.339502Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class TractImageDataset(torch.utils.data.Dataset):\n    def __init__(self, df, label=True, transforms=None, train=None):\n        self.df         = df\n        self.label      = label\n        self.img_paths  = df['image_paths']\n        self.msk_paths  = df['mask_path']\n        self.transforms = transforms\n        self.train      = train\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __load_img(self, path):\n        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n        img = img.astype('float32') # original is uint16\n        return data_transforms['train_resize'](image=img)['image']\n    \n    def __adjust_gamma(self, image, gamma):\n        image = ((image - np.min(image)) * 255 / (np.max(image) - np.min(image))).astype('uint8')\n        if not gamma:\n            return image\n        else:\n            invGamma = 1.0 / gamma\n            table = np.array([((i / 255.0) ** invGamma) * 255\n                for i in np.arange(0, 256)]).astype(\"uint8\")\n            # apply gamma correction using the lookup table\n            return cv2.LUT(image, table)\n    \n    def __load_msk(self, path, transform_type):\n        msk = np.load(path)\n        msk = msk.astype('float32')\n        msk = msk / 255.0\n        return data_transforms['train_resize'](image=np.zeros((*IMG_SIZE, 1), dtype=np.uint16), mask=msk)['mask']\n\n    def __getitem__(self, index):\n        img_paths = self.df.image_paths[index]\n        imgs = np.zeros((*IMG_SIZE, len(img_paths)), dtype=np.uint16)\n        for i, img_path in enumerate(img_paths):\n            img = self.__load_img(img_path)\n            imgs[..., i] = self.__adjust_gamma(img, gamma=2)\n        if self.label:\n            msk_path = self.msk_paths[index]\n            if self.train:\n                msk = self.__load_msk(msk_path, transform_type='train_resize')\n            else:\n                msk = self.__load_msk(msk_path, transform_type='valid_resize')\n            if self.train:\n                data = self.transforms['train'](image=imgs, mask=msk)\n                imgs = data['image']\n                msk  = data['mask']\n            imgs = imgs / np.max(imgs, axis=(0,1))\n            imgs = np.transpose(imgs, (2, 0, 1))\n            msk  = np.transpose(msk, (2, 0, 1))\n            return torch.FloatTensor(imgs), torch.FloatTensor(msk)\n        else:\n            if self.train:\n                data = self.transforms(image=imgs)\n                imgs = data['image']\n            return torch.FloatTensor(imgs)","metadata":{"id":"7Da6jkOZgVb-","execution":{"iopub.status.busy":"2022-07-13T18:28:35.029017Z","iopub.execute_input":"2022-07-13T18:28:35.029283Z","iopub.status.idle":"2022-07-13T18:28:35.046742Z","shell.execute_reply.started":"2022-07-13T18:28:35.029255Z","shell.execute_reply":"2022-07-13T18:28:35.045713Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Plot images + masks","metadata":{"id":"M7nzdnnCgVb-"}},{"cell_type":"code","source":"def show_image_plus_masks(img, masks):\n    img   = img.squeeze(dim=0)\n    masks = masks.squeeze(dim=0)\n    img   = torch.moveaxis(img, 0, -1)\n    fig   = plt.figure(figsize=(10, 5))\n    gs    = gridspec.GridSpec(nrows=1, ncols=2)\n\n    ax0 = fig.add_subplot(gs[0, 0])\n    im  = ax0.imshow(img, cmap='bone')\n    ax0.set_title(\"Image\", fontsize=15, weight='bold', y=1.02)\n\n    ax1 = fig.add_subplot(gs[0, 1])\n    ax1.set_title(\"Mask\", fontsize=15, weight='bold', y=1.02)\n\n    colors1 = ['yellow']\n    colors2 = ['green']\n    colors3 = ['red']\n\n    cmap1 = mpl.colors.ListedColormap(colors1)\n    cmap2 = mpl.colors.ListedColormap(colors2)\n    cmap3 = mpl.colors.ListedColormap(colors3)\n\n    l0 = ax1.imshow(img, cmap='bone')\n    l1 = ax1.imshow(np.ma.masked_where(masks[0]== 0,  masks[0]),cmap=cmap1, alpha=0.3)\n    l2 = ax1.imshow(np.ma.masked_where(masks[1]== 0,  masks[1]),cmap=cmap2, alpha=0.3)\n    l3 = ax1.imshow(np.ma.masked_where(masks[2]== 0,  masks[2]),cmap=cmap3, alpha=0.3)\n\n    _ = [ax.set_axis_off() for ax in [ax0,ax1]]\n\n    colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]\n    labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n    patches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\n    plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 14,\n               title='Mask Labels', title_fontsize=14, edgecolor=\"black\",  facecolor='#c5c6c7')\n    plt.suptitle(\"\", fontsize=20, weight='bold')\n    plt.show()","metadata":{"id":"2hHVR6vcgVb_","execution":{"iopub.status.busy":"2022-07-13T18:17:56.359411Z","iopub.execute_input":"2022-07-13T18:17:56.359907Z","iopub.status.idle":"2022-07-13T18:17:56.375503Z","shell.execute_reply.started":"2022-07-13T18:17:56.359872Z","shell.execute_reply":"2022-07-13T18:17:56.374737Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Data Loaders","metadata":{"id":"xXqoV2pigVb_"}},{"cell_type":"markdown","source":"__Beforehand, let's split DataFrame into train and validation__","metadata":{"id":"GWnldtXagVb_"}},{"cell_type":"code","source":"val_df_prepared   = train_df_prepared[train_df_prepared['fold'] == 0]\ntrain_df_prepared = train_df_prepared[train_df_prepared['fold'] != 0]","metadata":{"id":"UhodClgwgVcA","execution":{"iopub.status.busy":"2022-07-13T18:17:56.377576Z","iopub.execute_input":"2022-07-13T18:17:56.378315Z","iopub.status.idle":"2022-07-13T18:17:56.404510Z","shell.execute_reply.started":"2022-07-13T18:17:56.378279Z","shell.execute_reply":"2022-07-13T18:17:56.403827Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_df_prepared.segmentation.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:17:56.406611Z","iopub.execute_input":"2022-07-13T18:17:56.407049Z","iopub.status.idle":"2022-07-13T18:17:56.420568Z","shell.execute_reply.started":"2022-07-13T18:17:56.407011Z","shell.execute_reply":"2022-07-13T18:17:56.419767Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"val_df_prepared.segmentation.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:17:56.422417Z","iopub.execute_input":"2022-07-13T18:17:56.422600Z","iopub.status.idle":"2022-07-13T18:17:56.433034Z","shell.execute_reply.started":"2022-07-13T18:17:56.422577Z","shell.execute_reply":"2022-07-13T18:17:56.432285Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_df_prepared.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:17:56.434116Z","iopub.execute_input":"2022-07-13T18:17:56.434421Z","iopub.status.idle":"2022-07-13T18:17:56.440656Z","shell.execute_reply.started":"2022-07-13T18:17:56.434386Z","shell.execute_reply":"2022-07-13T18:17:56.439777Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"val_df_prepared.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:17:56.442247Z","iopub.execute_input":"2022-07-13T18:17:56.442562Z","iopub.status.idle":"2022-07-13T18:17:56.450574Z","shell.execute_reply.started":"2022-07-13T18:17:56.442491Z","shell.execute_reply":"2022-07-13T18:17:56.449803Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_df_prepared.reset_index(drop=True, inplace=True)\nval_df_prepared.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:17:56.451691Z","iopub.execute_input":"2022-07-13T18:17:56.452349Z","iopub.status.idle":"2022-07-13T18:17:56.459815Z","shell.execute_reply.started":"2022-07-13T18:17:56.452311Z","shell.execute_reply":"2022-07-13T18:17:56.458898Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# - Train and val loader\ntrain_dataset = TractImageDataset(train_df_prepared, label=True, transforms=data_transforms, train=True)\ntrain_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                                            num_workers=NUM_WORKERS, shuffle=True, drop_last=False)\nval_dataset   = TractImageDataset(val_df_prepared, label=True, transforms=data_transforms, train=False)\nval_loader    = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,\n                                            num_workers=NUM_WORKERS, shuffle=False, drop_last=False)","metadata":{"id":"KpYEL6I9gVcA","execution":{"iopub.status.busy":"2022-07-13T18:17:56.461173Z","iopub.execute_input":"2022-07-13T18:17:56.461588Z","iopub.status.idle":"2022-07-13T18:17:56.471323Z","shell.execute_reply.started":"2022-07-13T18:17:56.461549Z","shell.execute_reply":"2022-07-13T18:17:56.470526Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(\"TRAIN DATASET SAMPLE\")\nfor img_batch, mask_batch in train_loader:\n    cont = 0\n    for img, masks in zip(img_batch, mask_batch):\n        show_image_plus_masks(img, masks)\n        cont+=1\n        if cont == 10:\n            break\n    break","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:17:56.472421Z","iopub.execute_input":"2022-07-13T18:17:56.473134Z","iopub.status.idle":"2022-07-13T18:18:02.826728Z","shell.execute_reply.started":"2022-07-13T18:17:56.473084Z","shell.execute_reply":"2022-07-13T18:18:02.825925Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Create model","metadata":{"id":"t2j8DWpegVcA"}},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/640/1*ZS7xxm9jkGIcRnH3QKs02g.gif)","metadata":{"id":"AsQS2HKWgVcA"}},{"cell_type":"code","source":"# -- Create segmentation model with pretrained encoder\nmodel = smp.Unet(\n    encoder_name=ENCODER,\n    in_channels=3,\n    encoder_weights=ENCODER_WEIGHTS, \n    classes=3, \n    activation=None\n)","metadata":{"id":"qPM7UMUPgVcB","execution":{"iopub.status.busy":"2022-07-13T18:18:02.828607Z","iopub.execute_input":"2022-07-13T18:18:02.828839Z","iopub.status.idle":"2022-07-13T18:18:04.541144Z","shell.execute_reply.started":"2022-07-13T18:18:02.828808Z","shell.execute_reply":"2022-07-13T18:18:04.540367Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Loss functions","metadata":{"id":"FWw0Z93pgVcB"}},{"cell_type":"code","source":"# Define error criterion and optimize functions\ndice_loss = smp.losses.DiceLoss(mode='multilabel')\nbce_loss  = smp.losses.SoftBCEWithLogitsLoss()\ndef criterion(y_pred, y_true):\n    return 0.5 * dice_loss(y_pred, y_true) + 0.5 * bce_loss(y_pred, y_true)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 1e-03, weight_decay=0.001)\n# Define callbacks\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.3, verbose=True)","metadata":{"id":"_JZJjgbVgVcB","execution":{"iopub.status.busy":"2022-07-13T18:19:22.367772Z","iopub.execute_input":"2022-07-13T18:19:22.368481Z","iopub.status.idle":"2022-07-13T18:19:22.379092Z","shell.execute_reply.started":"2022-07-13T18:19:22.368446Z","shell.execute_reply":"2022-07-13T18:19:22.378346Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy: Intersection over Union or IoU","metadata":{"id":"A2STtOudgVcB"}},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n    y_true = y_true.to(torch.float32)\n    y_pred = (y_pred>thr).to(torch.float32)\n    inter = (y_true*y_pred).sum(dim=dim)\n    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n    dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n    return dice","metadata":{"id":"uS5MTCavgVcB","execution":{"iopub.status.busy":"2022-07-13T18:19:26.410475Z","iopub.execute_input":"2022-07-13T18:19:26.410767Z","iopub.status.idle":"2022-07-13T18:19:26.417037Z","shell.execute_reply.started":"2022-07-13T18:19:26.410717Z","shell.execute_reply":"2022-07-13T18:19:26.416237Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"dice_coef(torch.round(torch.sigmoid(torch.rand(10,3,256,256))).int(), \n            torch.round(torch.sigmoid(torch.rand(10,3,256,256))).int())","metadata":{"id":"6LE8avN9gVcC","execution":{"iopub.status.busy":"2022-07-13T18:19:27.553586Z","iopub.execute_input":"2022-07-13T18:19:27.554080Z","iopub.status.idle":"2022-07-13T18:19:27.669539Z","shell.execute_reply.started":"2022-07-13T18:19:27.554030Z","shell.execute_reply":"2022-07-13T18:19:27.668759Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Define train and validation functions","metadata":{"id":"t5gMgm_mgVcC"}},{"cell_type":"code","source":"# Define train function\ndef train(train_data, model, criterion):\n    print('Training...')\n    model.train()\n    counter = 0\n    correct = 0\n    train_running_loss  = 0.0\n    train_running_dice  = 0.0\n    total               = 0.0\n    pbar = tqdm(train_data)\n    for input_data, label in pbar:\n        # Switch to GPU if available\n        if torch.cuda.is_available():\n            input_data, label = input_data.cuda(), label.cuda()\n        optimizer.zero_grad()\n        outputs = model(input_data)\n\n        # Apply sigmoid activation to get all the outputs between 0 and 1\n        outputs_sig  = nn.Sigmoid()(outputs)\n        predicted    = torch.round(outputs_sig)\n        mean_dice    = dice_coef(label, predicted)\n        \n        # Loss\n        loss = criterion(outputs.cpu(), label.cpu())\n        loss_item = float(loss.detach().item())\n        counter += 1\n        pbar.set_description(\"Loss: {} - Dice coef: {}\".format(loss_item, mean_dice.detach().cpu()))\n        \n        train_running_loss += loss_item\n        train_running_dice += mean_dice.detach().cpu()\n        \n        # Backpropagation\n        loss.backward()\n        \n        # Update optimizer parameters\n        optimizer.step()\n        \n    train_loss = train_running_loss  / counter\n    train_dice  = train_running_dice / counter\n    torch.cuda.empty_cache()\n    gc.collect()\n    return train_loss, train_dice","metadata":{"id":"-47PwCPVgVcC","execution":{"iopub.status.busy":"2022-07-13T18:19:28.159906Z","iopub.execute_input":"2022-07-13T18:19:28.160485Z","iopub.status.idle":"2022-07-13T18:19:28.170688Z","shell.execute_reply.started":"2022-07-13T18:19:28.160442Z","shell.execute_reply":"2022-07-13T18:19:28.169702Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Define val function\ndef val(val_data, model, criterion):\n    print('Validating...')\n    model.eval()\n    counter = 0\n    val_running_loss = 0.0\n    val_running_dice = 0.0\n    val_dice         = 0.0\n    pbar = tqdm(val_data)\n    with torch.no_grad():\n        for input_data, label in pbar:\n            # Again, switch to GPU if available\n            if torch.cuda.is_available():\n                input_data, label = input_data.cuda(), label.cuda()\n            outputs  = model(input_data)\n\n            # Apply sigmoid activation to get all the outputs between 0 and 1\n            outputs_sig = nn.Sigmoid()(outputs)\n            predicted   = torch.round(outputs_sig)\n            mean_dice    = dice_coef(label, predicted)\n\n            # Loss\n            counter += 1\n            loss_item = criterion(outputs.cpu(), label.cpu()).detach().item()\n            pbar.set_description(\"Loss: {} - Dice coef: {}\".format(loss_item, mean_dice.detach().cpu()))\n            \n            val_running_loss += loss_item\n            val_running_dice += mean_dice.detach().cpu()\n        \n    val_loss = val_running_loss  / counter\n    val_dice  = val_running_dice / counter\n    torch.cuda.empty_cache()\n    gc.collect()\n    return val_loss, val_dice","metadata":{"id":"m4IYexfvgVcC","execution":{"iopub.status.busy":"2022-07-13T18:19:29.266678Z","iopub.execute_input":"2022-07-13T18:19:29.267002Z","iopub.status.idle":"2022-07-13T18:19:29.275818Z","shell.execute_reply.started":"2022-07-13T18:19:29.266968Z","shell.execute_reply":"2022-07-13T18:19:29.275037Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"run = wandb.init(project='uw-maddison-gi-tract', \n                 name='unet-2022-07-07', \n                 group='unet-224x224-model')","metadata":{"id":"lBFtiYc1gVcD","execution":{"iopub.status.busy":"2022-07-07T19:06:16.702607Z","iopub.execute_input":"2022-07-07T19:06:16.70286Z","iopub.status.idle":"2022-07-07T19:06:20.079922Z","shell.execute_reply.started":"2022-07-07T19:06:16.702833Z","shell.execute_reply":"2022-07-07T19:06:20.079008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###### -- Start the training and validation\ntrain_loss     = []\ntrain_accuracy = []\nvalid_loss     = []\nvalid_accuracy = []\ntotal_train_predictions = []\ntotal_val_predictions   = []\n\nbest_val_loss = float('inf')\nbest_val_auc  = float(0)\n\npatient_counter = 0\n\nif torch.cuda.is_available():\n    model = model.cuda()\n\n# -- To automatically log gradients\nwandb.watch(model, log_freq=100)\n\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch+1} of {EPOCHS}\")\n    train_epoch_loss, train_epoch_accuracy = train(\n        train_loader, model, criterion\n    )\n    val_epoch_loss, val_epoch_accuracy = val(\n        val_loader, model, criterion\n    )\n    \n    # Call ReduceLR Callback (after validation step)\n    scheduler.step(val_epoch_loss)\n    \n    if best_val_loss - val_epoch_loss >= LOSS_IMPROVE:\n        print(\"Val mean loss has improved. From {} to {}. Saving model...\".format(best_val_loss, val_epoch_loss))\n        best_val_loss   = val_epoch_loss\n        patient_counter = 0\n        torch.save(model, MODEL_NAME)\n        wandb.save(MODEL_NAME)\n    else:\n        print(\"Val mean loss did not improve\")\n        patient_counter+=1\n        if patient_counter == PATIENT:\n            break\n            \n    print(f\"Train mean Dice: {train_epoch_accuracy:.4f}\")\n    print(f'Val mean Dice: {val_epoch_accuracy:.4f}')\n    print(f\"Train mean Loss: {train_epoch_loss:.4f}\")\n    print(f'Val mean Loss: {val_epoch_loss:.4f}')\n    print(\"-\"*80)\n            \n    wandb.log({\"Train Loss\": train_epoch_loss, \n               \"Valid Loss\": val_epoch_loss,\n               \"Train Dice\": train_epoch_accuracy,\n               \"Valid Dice\": val_epoch_accuracy,\n               \"LR\":optimizer.param_groups[0]['lr']})\n        \n    train_loss.append(train_epoch_loss)\n    train_accuracy.append(train_epoch_accuracy)\n    valid_loss.append(val_epoch_loss)\n    valid_accuracy.append(val_epoch_accuracy)\n\n# Testing some validation images","metadata":{"id":"vjzgBp0PgVcG","execution":{"iopub.status.busy":"2022-07-07T19:06:33.633401Z","iopub.execute_input":"2022-07-07T19:06:33.63367Z","iopub.status.idle":"2022-07-08T01:03:19.850629Z","shell.execute_reply.started":"2022-07-07T19:06:33.633642Z","shell.execute_reply":"2022-07-08T01:03:19.849887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__FPN architecture__","metadata":{}},{"cell_type":"code","source":"model = torch.load('../input/fpn-2022-06-18-efficientnet-b1/03_uw_madison_seg_fpn_25d_bce_dice_loss_error_plus_data_aug.pth')\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint(\"Total number of parameters: {}\".format(params))","metadata":{"id":"UoLz2oQ8gVcG","execution":{"iopub.status.busy":"2022-07-13T18:20:50.257980Z","iopub.execute_input":"2022-07-13T18:20:50.258599Z","iopub.status.idle":"2022-07-13T18:20:50.369820Z","shell.execute_reply.started":"2022-07-13T18:20:50.258563Z","shell.execute_reply":"2022-07-13T18:20:50.368903Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"__UNet architecture__","metadata":{}},{"cell_type":"code","source":"model = torch.load('../input/efficientnet-b1-25d-gamma-contrast-stride-1/03_uw_madison_seg_unet_efficientnetb1_25d_dice_loss_error_plus_data_aug (1).pth')\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint(\"Total number of parameters: {}\".format(params))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:27:31.959251Z","iopub.execute_input":"2022-07-13T18:27:31.959584Z","iopub.status.idle":"2022-07-13T18:27:32.737410Z","shell.execute_reply.started":"2022-07-13T18:27:31.959487Z","shell.execute_reply":"2022-07-13T18:27:32.736579Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Dice coef","metadata":{"id":"VEvIc0eKgVcH"}},{"cell_type":"markdown","source":"![Dice loss formula](https://miro.medium.com/max/1400/1*Z1hkDvyhFBogT9EkzVkX2A.png)","metadata":{"id":"mYp6chNHgVcH"}},{"cell_type":"code","source":"def dice_coef_by_label(y_true, y_pred, dim=(1,2), epsilon=0.001):\n    dice_score_list = [0.,0.,0.]\n    for label in range(0,3):\n        inter = (y_true[:,label,...]*y_pred[:,label,...]).sum(dim=dim)\n        den   = y_true[:,label,...].sum(dim=dim) + y_pred[:,label,...].sum(dim=dim)\n        dice  = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(0))\n        dice_score_list[label] += dice\n    return dice_score_list\n\ndef competition_score(y_true, y_pred):\n    y_true = torch.round(y_true).int() # -- E.g (32, 3, 224, 224)\n    y_pred = torch.round(y_pred).int() # -- E.g (32, 3, 224, 224)\n\n    dice_score = dice_coef(y_true, y_pred)\n    return dice_score","metadata":{"id":"Lumho3t0gVcH","execution":{"iopub.status.busy":"2022-07-13T18:21:05.072670Z","iopub.execute_input":"2022-07-13T18:21:05.072951Z","iopub.status.idle":"2022-07-13T18:21:05.083765Z","shell.execute_reply.started":"2022-07-13T18:21:05.072920Z","shell.execute_reply":"2022-07-13T18:21:05.083056Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Define val function\ndef test(test_data, model, criterion):\n    print('Testing...')\n    model.eval()\n    counter = 0\n    test_competition_score = 0.0\n    total_dice_score_list  = [0.,0.,0.]\n    total_dice_score_list_acc = []\n    images_list = []\n    pred_list = []\n    real_mask_list = []\n    pbar = tqdm(test_data)\n    dice_coef_list = []\n    original_img = []\n    \n    kernel = np.ones((8,8),np.uint8)\n    if torch.cuda.is_available():\n        model = model.cuda()\n    with torch.no_grad():\n        for input_data, label in pbar:\n            # Again, switch to GPU if available\n            if torch.cuda.is_available():\n                input_data, label = input_data.cuda(), label.cuda()\n            outputs  = model(input_data)\n\n            # Apply sigmoid activation to get all the outputs between 0 and 1\n            outputs_sig = nn.Sigmoid()(outputs)\n            predicted   = torch.round(outputs_sig)\n            predicted_np= np.zeros(((1, 3, 224, 224)))\n            for i in range(0,3):\n                predicted_np[0,i,...] = cv2.morphologyEx(predicted[0,i,...].cpu().numpy(), cv2.MORPH_CLOSE, kernel)\n            predicted = torch.from_numpy(predicted_np).cuda()\n            # Competition score\n            competition_score = criterion(label.cpu(), predicted.cpu()).detach().cpu()\n            \n            if competition_score < 0.1:\n                original_img.append(input_data.cpu())\n                pred_list.append(predicted.cpu())\n                real_mask_list.append(label.cpu())\n            \n            dice_coef = dice_coef_by_label(label.cpu(), predicted.cpu())\n            dice_coef_list.append(dice_coef)\n            total_dice_score_list = np.add(total_dice_score_list, dice_coef)\n            #if torch.cuda.is_available():\n            #    pbar.set_description(\"Dice score: {}\".format(competition_score))\n            counter += 1\n        \n    avg_dice = total_dice_score_list / counter\n    torch.cuda.empty_cache()\n    gc.collect()\n    return avg_dice, pred_list, real_mask_list, original_img, dice_coef_list","metadata":{"id":"pcHiVICngVcH","execution":{"iopub.status.busy":"2022-07-13T18:21:06.547193Z","iopub.execute_input":"2022-07-13T18:21:06.547621Z","iopub.status.idle":"2022-07-13T18:21:06.564748Z","shell.execute_reply.started":"2022-07-13T18:21:06.547582Z","shell.execute_reply":"2022-07-13T18:21:06.563878Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Average Dice score by label: large bowel, small bowel and stomach","metadata":{"id":"DJML6m9egVcI"}},{"cell_type":"markdown","source":"### Validation","metadata":{"id":"smIJSpdPgVcI"}},{"cell_type":"markdown","source":"__Non-empty masks__","metadata":{}},{"cell_type":"code","source":"# -- Change BATCH SIZE to 1\nval_dataset   = TractImageDataset(val_df_prepared[~val_df_prepared['empty']].reset_index(drop=True), \n                                  label=True, transforms=data_transforms, train=False)\nval_loader    = torch.utils.data.DataLoader(val_dataset, batch_size=1,\n                                            num_workers=NUM_WORKERS, shuffle=False, drop_last=False)","metadata":{"id":"lzAjuZC3gVcI","execution":{"iopub.status.busy":"2022-07-13T18:28:52.545026Z","iopub.execute_input":"2022-07-13T18:28:52.545502Z","iopub.status.idle":"2022-07-13T18:28:52.555719Z","shell.execute_reply.started":"2022-07-13T18:28:52.545463Z","shell.execute_reply":"2022-07-13T18:28:52.554562Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"__FPN__","metadata":{}},{"cell_type":"code","source":"avg_dice, pred_list, real_mask_list, original_img, dice_coef_list = test(val_loader, model, competition_score)\nfor label, dice in zip(['Large bowel', 'Small bowel', 'Stomach'], avg_dice):\n    print(\"Label: {} - Average Dice score: {}\".format(label, dice))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:21:26.834664Z","iopub.execute_input":"2022-07-13T18:21:26.834964Z","iopub.status.idle":"2022-07-13T18:24:18.359360Z","shell.execute_reply.started":"2022-07-13T18:21:26.834932Z","shell.execute_reply":"2022-07-13T18:24:18.358621Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"__UNet__","metadata":{}},{"cell_type":"code","source":"avg_dice, pred_list, real_mask_list, original_img, dice_coef_list = test(val_loader, model, competition_score)\nfor label, dice in zip(['Large bowel', 'Small bowel', 'Stomach'], avg_dice):\n    print(\"Label: {} - Average Dice score: {}\".format(label, dice))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:29:06.322730Z","iopub.execute_input":"2022-07-13T18:29:06.323468Z","iopub.status.idle":"2022-07-13T18:31:48.900029Z","shell.execute_reply.started":"2022-07-13T18:29:06.323427Z","shell.execute_reply":"2022-07-13T18:31:48.899208Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"__Empty masks__","metadata":{}},{"cell_type":"code","source":"# -- Change BATCH SIZE to 1\nval_dataset   = TractImageDataset(val_df_prepared[val_df_prepared['empty']].reset_index(drop=True), \n                                  label=True, transforms=data_transforms, train=False)\nval_loader    = torch.utils.data.DataLoader(val_dataset, batch_size=1,\n                                            num_workers=NUM_WORKERS, shuffle=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:31:48.901988Z","iopub.execute_input":"2022-07-13T18:31:48.902812Z","iopub.status.idle":"2022-07-13T18:31:48.913034Z","shell.execute_reply.started":"2022-07-13T18:31:48.902772Z","shell.execute_reply":"2022-07-13T18:31:48.911988Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"__FPN__","metadata":{}},{"cell_type":"code","source":"avg_dice, pred_list, real_mask_list, original_img, dice_coef_list = test(val_loader, model, competition_score)\nfor label, dice in zip(['Large bowel', 'Small bowel', 'Stomach'], avg_dice):\n    print(\"Label: {} - Average Dice score: {}\".format(label, dice))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:24:18.375702Z","iopub.execute_input":"2022-07-13T18:24:18.376014Z","iopub.status.idle":"2022-07-13T18:27:31.950127Z","shell.execute_reply.started":"2022-07-13T18:24:18.375976Z","shell.execute_reply":"2022-07-13T18:27:31.949378Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"__UNet__","metadata":{}},{"cell_type":"code","source":"avg_dice, pred_list, real_mask_list, original_img, dice_coef_list = test(val_loader, model, competition_score)\nfor label, dice in zip(['Large bowel', 'Small bowel', 'Stomach'], avg_dice):\n    print(\"Label: {} - Average Dice score: {}\".format(label, dice))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:31:48.915549Z","iopub.execute_input":"2022-07-13T18:31:48.915763Z","iopub.status.idle":"2022-07-13T18:34:58.111607Z","shell.execute_reply.started":"2022-07-13T18:31:48.915738Z","shell.execute_reply":"2022-07-13T18:34:58.110727Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:34:58.113758Z","iopub.execute_input":"2022-07-13T18:34:58.114246Z","iopub.status.idle":"2022-07-13T18:34:58.118966Z","shell.execute_reply.started":"2022-07-13T18:34:58.114204Z","shell.execute_reply":"2022-07-13T18:34:58.118071Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Export patient sample to DICOM","metadata":{}},{"cell_type":"code","source":"patient_sample_files = glob.glob('../input/uw-madison-gi-tract-image-segmentation/train/case123/case123_day20/scans/*')\npatient_sample_files.sort()\npatient_sample_files\nimage_sample = np.array([cv2.imread(file, cv2.IMREAD_UNCHANGED) for file in patient_sample_files])","metadata":{"execution":{"iopub.status.busy":"2022-07-07T16:08:51.128944Z","iopub.execute_input":"2022-07-07T16:08:51.129192Z","iopub.status.idle":"2022-07-07T16:08:52.316195Z","shell.execute_reply.started":"2022-07-07T16:08:51.129158Z","shell.execute_reply":"2022-07-07T16:08:52.315432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir sample","metadata":{"execution":{"iopub.status.busy":"2022-07-07T16:08:52.317826Z","iopub.execute_input":"2022-07-07T16:08:52.318107Z","iopub.status.idle":"2022-07-07T16:08:53.031272Z","shell.execute_reply.started":"2022-07-07T16:08:52.318071Z","shell.execute_reply":"2022-07-07T16:08:53.030277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pydicom\nfrom pydicom.dataset import Dataset, FileDataset\nfrom pydicom.uid import ExplicitVRLittleEndian\nimport pydicom._storage_sopclass_uids\n\nfor i, image2d in tqdm(enumerate(image_sample)):\n    # Populate required values for file meta information\n\n    meta = pydicom.Dataset()\n    meta.MediaStorageSOPClassUID = pydicom._storage_sopclass_uids.MRImageStorage\n    meta.MediaStorageSOPInstanceUID = pydicom.uid.generate_uid()\n    meta.TransferSyntaxUID = pydicom.uid.ExplicitVRLittleEndian  \n\n    ds = Dataset()\n    ds.file_meta = meta\n\n    ds.is_little_endian = True\n    ds.is_implicit_VR = False\n\n    ds.SOPClassUID = pydicom._storage_sopclass_uids.MRImageStorage\n    ds.PatientName = \"Test^GI^Tract^Image^Segmentation\"\n    ds.PatientID = \"123456\"\n\n    ds.Modality = \"MR\"\n    ds.SeriesInstanceUID = pydicom.uid.generate_uid()\n    ds.StudyInstanceUID = pydicom.uid.generate_uid()\n    ds.FrameOfReferenceUID = pydicom.uid.generate_uid()\n\n    ds.BitsStored = 16\n    ds.BitsAllocated = 16\n    ds.SamplesPerPixel = 1\n    ds.HighBit = 15\n\n    ds.ImagesInAcquisition = \"116\"\n\n    ds.Rows = image2d.shape[0]\n    ds.Columns = image2d.shape[1]\n    ds.InstanceNumber = 1\n\n    ds.ImagePositionPatient = r\"0\\0\\1\"\n    ds.ImageOrientationPatient = r\"1\\0\\0\\0\\-1\\0\"\n    ds.ImageType = r\"ORIGINAL\\PRIMARY\\AXIAL\"\n\n    ds.RescaleIntercept = \"0\"\n    ds.RescaleSlope = \"1\"\n    ds.PixelSpacing = r\"1\\1\"\n    ds.PhotometricInterpretation = \"MONOCHROME2\"\n    ds.PixelRepresentation = 1\n\n    pydicom.dataset.validate_file_meta(ds.file_meta, enforce_standard=True)\n    ds.PixelData = image2d.tobytes()\n    ds.save_as(r\"./sample/sample_slice_{}.dcm\".format(i))","metadata":{"execution":{"iopub.status.busy":"2022-07-07T16:10:30.417599Z","iopub.execute_input":"2022-07-07T16:10:30.418331Z","iopub.status.idle":"2022-07-07T16:10:31.077272Z","shell.execute_reply.started":"2022-07-07T16:10:30.418287Z","shell.execute_reply":"2022-07-07T16:10:31.076438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r sample.zip ./sample","metadata":{"execution":{"iopub.status.busy":"2022-07-07T16:10:49.854099Z","iopub.execute_input":"2022-07-07T16:10:49.854712Z","iopub.status.idle":"2022-07-07T16:10:52.105564Z","shell.execute_reply.started":"2022-07-07T16:10:49.854674Z","shell.execute_reply":"2022-07-07T16:10:52.104796Z"},"trusted":true},"execution_count":null,"outputs":[]}]}